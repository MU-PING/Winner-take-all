# Winner_Take_All
## 程式簡介
### 使用說明：
> 又稱 Winner Take All Learning Rule，透過視覺化界面展示其學習與聚類過程

* 「學習率」與「訓練次數」皆可手動設定。

* 「神經元個數」即代表要分成幾個類別，同時會產生對應個類別的測試資料，例如：5即分成5類

* 可選擇不同的得勝標準：「歐基里德距離」、「cosθ」、「內積」

* 「開始訓練」產生最終聚類結果
### 範例圖：
![](https://i.imgur.com/OsGVBEN.png)

## Winner Take All Learning Rule 演算法
### 演算法簡介
> 一種用於「**聚類**」的「**非監督式學習**」演算法
* 使用**競爭式學習法**的**單層類神經網路**，也被稱為 Kohonen learning rule。

* 數據再神經元間競爭，若得勝，則聚類到該類

* 不同神經元即代表不同類別

* 得勝標準有很多種類，每個效果都不一樣

* **神經網路架構圖：**  
  <img src="https://i.imgur.com/rQCmg1H.png" width="207" height="230">
### 演算法步驟：
#### 1. 競爭階段( Competitive phase ) - 選出得勝者( winner )
  假設 x 為輸入[ x<sub>1</sub>, x<sub>2</sub>, ..., x<sub>p</sub> ]；  w<sub>j</sub> 為第 j 個神經元的權重[ w<sub>j1</sub>, w<sub>j2</sub>, ..., w<sub>jp</sub> ]。  
  依照下列三種衡量方法來計算「第 j 個神經元的分數」，再依照不同標準選取得勝者：
  1. **歐基里德距離**
      * 獲勝標準： 最小者 
      * 評分公式： | x - w<sub>j</sub> |
  2. **cosθ**
      * 獲勝標準： 最大者 
      * 評分公式： x · w<sub>j</sub><sup>T</sup> / | x | | c |
  3. **內積**  
      * 獲勝標準： 最大者 
      * 評分公式： x · w<sub>j</sub><sup>T</sup>
> **不同輸入 x 、 y 若在同個神經元得勝，將 x 、 y 歸屬同一類。**  
#### 2. 獎勵階段( Reward phase ) - 調整「得勝者」鍵結值
  選出得勝的神經元後對該神經元更新 ( 假設為第k個 )；沒有得勝的神經元不用更新。n 表疊代次數、lr 表學習效率  
* w<sub>k</sub>( n+1 ) = w<sub>k</sub>( n ) + lr( x - w<sub>k</sub>( n ))
> **目的是讓 x 下次輸入時更容易在第k個神經元得勝( 換句話說就是讓 x 更容易被聚類為該類別 )**
#### 3. 疊代階段( Iteration phase ) - 檢查停止訓練條件是否吻合
簡而言之就是決定訓練何時停止，主要有以下二方法：
1. 鍵結值的改變量小於一固定閥值，訓練停止，反之繼續

2. 設定Epoch  

如果未達停止標準，回到步驟A繼續訓練。
  
### 特性分析：

1. 不同衡量方法會影響整個「聚類結果」與「群集的幾何特性」。

2. 鍵結值的初始化會影響聚類結果，因為某些神經元可能永遠沒有得勝機會，導致大部分資料被聚類到優勢族群，解決方法有：
    * 所有神經元的鍵結值向量隨機初始化成一部分的輸入向量 
    
    * 懲罰得勝機率較高的神經元，讓其他神經元有機會 
    
    * 在獎勵階段時更新全部神經元的鍵結值，但得勝者更新的最多  

3. 神經元個數即代表聚類的種類，如果設定不對( 不等於實際資料的群聚數目 )，可能會將資料錯誤聚類。

4. 此演算法「效果」與k-means演算法類似，都可以用來做「向量量化」(vector quantization)的工作
### 結論：
此專案不著重在分群的Performance上，而是透過程式練習一些「非監督式學習」中很基礎的分群概念，以利延伸。
